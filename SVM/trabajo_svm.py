# -*- coding: utf-8 -*-
"""Trabajo_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IVf6KTRTI_G8PDLQrDV1RGab3j1qPABb

CARGA DE IMÁGENES
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""CARGA DE PAQUETES"""

# Commented out IPython magic to ensure Python compatibility.
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
# %matplotlib notebook
from sklearn import svm, metrics, datasets
from sklearn.utils import Bunch
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.externals import joblib
import skimage
from skimage.io import imread
from skimage.transform import resize
from skimage.color import rgb2gray
import os
import pickle

"""CARGA DE IMÁGENES"""

def load_image_files(container_path, dimension=(100, 100)):
    """
    Load image files with categories as subfolder names 
    which performs like scikit-learn sample dataset
    
    Parameters
    ----------
    container_path : string or unicode
        Path to the main folder holding one subfolder per category
    dimension : tuple
        size to which image are adjusted to
        
    Returns
    -------
    Bunch
    """
    image_dir = Path(container_path)
    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]
    categories = [fo.name for fo in folders]
    descr = "A image classification dataset"
    images = []
    flat_data = []
    target = []
    for i, direc in enumerate(folders):
        for file in direc.iterdir():
            img = skimage.io.imread(file)
            img = rgb2gray(img)
            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')
            flat_data.append(img_resized.flatten()) 
            #print(img_resized.flatten())
            images.append(img_resized)
            #print(img_resized)
            if i==0:
              target.append('Pulmon Canceroso')
            else:
              target.append('Pulmon Sano')
            #print(i)
    flat_data = np.array(flat_data)
    target = np.array(target)
    images = np.array(images)

    return Bunch(data=flat_data,
                 target=target,
                 target_names=categories,
                 images=images,
                 DESCR=descr)

image_dataset_train = load_image_files("gdrive/MyDrive/Dataset/Entrenamiento/")

"""ENTRENAMIENTO DE DATOS"""

#X_train, X_test, y_train, y_test = train_test_split(image_dataset_train.data, image_dataset_train.target, test_size=0.3,random_state=109)
X_train = image_dataset_train.data
Y_train = image_dataset_train.target
param_grid = [
  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
 ]
svc = svm.SVC()
clf = GridSearchCV(svc, param_grid)
clf.fit(X_train, Y_train)

pickle.dump(clf, open('gdrive/MyDrive/Dataset/modelo/modelo_svm.pk1','wb'))

"""PREDICCIÓN DE PRUEBA"""

image_dataset_test = load_image_files("gdrive/MyDrive/Dataset/Prueba/")

modelo = pickle.load(open("gdrive/MyDrive/Dataset/modelo/modelo_svm.pk1","rb"))
X_test = image_dataset_test.data
Y_test = image_dataset_test.target
#y_pred = clf.predict(X_test)
y_pred = modelo.predict(X_test)

"""REPORTE DE PRUEBA"""

#print("Classification report for - \n{}:\n{}\n".format(clf, metrics.classification_report(Y_test, y_pred)))
print("Classification report for - \n{}:\n{}\n".format(modelo, metrics.classification_report(Y_test, y_pred)))

"""PREDICCIÓN DE IMAGEN NUEVA"""

def load_image_validacion(container_path, dimension=(100, 100)):
    image_dir = Path(container_path)
    listado_valid = os.listdir(image_dir)
    categories = ["Pulmon Canceroso", "Pulmon Sano"]
    descr = "Image validation set"
    images = []
    flat_data = []
    target = []
    for i in (listado_valid):
      if i != '.ipynb_checkpoints':
        aux = container_path+i
        img = skimage.io.imread(aux)
        img = rgb2gray(img)
        img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')
        flat_data.append(img_resized.flatten()) 
        images.append(img_resized)
        if i[0:6]=='NORMAL':
          target.append('Pulmon Sano')
        else:
          target.append('Pulmon Canceroso')
        aux = ''
    flat_data = np.array(flat_data)
    target = np.array(target)
    images = np.array(images)

    return Bunch(data=flat_data,
                 target=target,
                 target_names=categories,
                 images=images,
                 DESCR=descr)

image_dataset_nva = load_image_validacion("gdrive/MyDrive/Dataset/Validacion/")
X_nva = image_dataset_nva.data
Y_nva = image_dataset_nva.target
modelo = pickle.load(open("gdrive/MyDrive/Dataset/modelo/modelo_svm.pk1","rb"))
nva_pred = modelo.predict(X_nva)

"""REPORTE DE IMAGEN NUEVA"""

print("Classification report for - \n{}:\n{}\n".format(modelo, metrics.classification_report(Y_nva, nva_pred)))